{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "codes = df[\"code\"].tolist()\n",
    "print(len(codes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001 8000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lengths = sorted([len(code) for code in codes])\n",
    "\n",
    "print(lengths[0], lengths[-1])\n",
    "plt.hist(lengths)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = []\n",
    "for label in df[\"label\"]:\n",
    "    splitted.extend(str(label).split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "823715"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_labels = list(df[\"label\"])\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(shuffled_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_first = []\n",
    "h = len(shuffled_labels) // 2\n",
    "for label in shuffled_labels[:h]:\n",
    "    in_first.extend(str(label).split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_second = []\n",
    "for label in shuffled_labels[h:]:\n",
    "    in_second.extend(str(label).split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9677047429486868\n",
      "411980\n"
     ]
    }
   ],
   "source": [
    "set_in_first = set(in_first)\n",
    "intersection = sum(int(x in set_in_first) for x in in_second)\n",
    "print(intersection / len(in_second))\n",
    "print(len(in_second))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt = {}\n",
    "for label in splitted:\n",
    "    cnt[label] = cnt.get(label, 0) + 1\n",
    "\n",
    "freqs = sorted(list(cnt.values()))[::-1]\n",
    "cum = [0] * (len(freqs) + 1)\n",
    "for i in range(len(freqs)):\n",
    "    cum[i + 1] = cum[i] + freqs[i]\n",
    "cum = [x / cum[-1] for x in cum]\n",
    "plt.plot(cum)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18245\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(splitted)\n",
    "frequent = []\n",
    "for k, v in counter.items():\n",
    "    if v > 1:\n",
    "        frequent.append(k)\n",
    "\n",
    "print(len(frequent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test', 77195),\n",
       " ('get', 32099),\n",
       " ('set', 8512),\n",
       " ('to', 7388),\n",
       " ('create', 6196),\n",
       " ('with', 5564),\n",
       " ('data', 5373),\n",
       " ('is', 4950),\n",
       " ('from', 4856),\n",
       " ('add', 4737)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up class\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handle state transition\n",
      "====================\n",
      "\"\"\"opentrons.hardware_control.estop_state: module to manage estop state machine on OT-3.\"\"\"\n",
      "\n",
      "from typing import List, Optional\n",
      "\n",
      "from opentrons_hardware.hardware_control.estop.detector import (\n",
      "    EstopSummary,\n",
      "    EstopDetector,\n",
      ")\n",
      "\n",
      "from opentrons.hardware_control.types import (\n",
      "    EstopState,\n",
      "    EstopPhysicalStatus,\n",
      "    EstopAttachLocation,\n",
      "    EstopStateNotification,\n",
      "    HardwareEventHandler,\n",
      ")\n",
      "\n",
      "\n",
      "class EstopStateMachine:\n",
      "    \"\"\"Class to manage global Estop state.\"\"\"\n",
      "\n",
      "    def __init__(self, detector: Optional[EstopDetector]) -> None:\n",
      "        \"\"\"Create a new EstopStateMachine.\n",
      "\n",
      "        If detector is None, the state machine will be initialized in\n",
      "        a happy state (Disengaged, both estops detected) until it is\n",
      "        hooked up to a valid detector.\n",
      "        \"\"\"\n",
      "        self._detector: Optional[EstopDetector] = None\n",
      "        self._state: EstopState = EstopState.DISENGAGED\n",
      "        # Start off in a happy state until a detector is added\n",
      "        self._summary = EstopSummary(\n",
      "            left_detected=True, right_detected=True, engaged=False\n",
      "        )\n",
      "        if detector is not None:\n",
      "            self.subscribe_to_detector(detector=detector)\n",
      "        self._listeners: List[HardwareEventHandler] = []\n",
      "\n",
      "    def subscribe_to_detector(self, detector: EstopDetector) -> None:\n",
      "        \"\"\"Configure the estop state machine to listen to a detector.\n",
      "\n",
      "        This function will also transition the state based on the current\n",
      "        status of the detector.\"\"\"\n",
      "        if self._detector is not None:\n",
      "            self._detector.remove_listener(self.detector_listener)\n",
      "        self._detector = detector\n",
      "        detector.add_listener(listener=self.detector_listener)\n",
      "        self.METHOD_NAME(new_summary=detector.status)\n",
      "\n",
      "    def __del__(self) -> None:\n",
      "        if self._detector is not None:\n",
      "            self._detector.remove_listener(self.detector_listener)\n",
      "\n",
      "    def add_listener(self, listener: HardwareEventHandler) -> None:\n",
      "        \"\"\"Add a hardware event listener for estop event changes.\"\"\"\n",
      "        if listener not in self._listeners:\n",
      "            self._listeners.append(listener)\n",
      "\n",
      "    def remove_listener(self, listener: HardwareEventHandler) -> None:\n",
      "        \"\"\"Remove an existing hardware event listener for estop detector changes.\"\"\"\n",
      "        if listener in self._listeners:\n",
      "            self._listeners.remove(listener)\n",
      "\n",
      "    def detector_listener(self, summary: EstopSummary) -> None:\n",
      "        \"\"\"Callback from the detector.\"\"\"\n",
      "        self.METHOD_NAME(new_summary=summary)\n",
      "\n",
      "    @staticmethod\n",
      "    def _transition_from_physically_engaged(summary: EstopSummary) -> EstopState:\n",
      "        if not summary.engaged:\n",
      "            # Estop disengaged, move to Logically Engaged\n",
      "            return EstopState.LOGICALLY_ENGAGED\n",
      "        return EstopState.PHYSICALLY_ENGAGED\n",
      "\n",
      "    @staticmethod\n",
      "    def _transition_from_disengaged(summary: EstopSummary) -> EstopState:\n",
      "        if summary.engaged:\n",
      "            # Estop engaged, move to physically engaged\n",
      "            return EstopState.PHYSICALLY_ENGAGED\n",
      "        if summary.left_detected or summary.right_detected:\n",
      "            # An estop is still plugged in, stay disengaged\n",
      "            return EstopState.DISENGAGED\n",
      "        # Everything unplugged, block all action\n",
      "        return EstopState.NOT_PRESENT\n",
      "\n",
      "    @staticmethod\n",
      "    def _transition_from_not_present(summary: EstopSummary) -> EstopState:\n",
      "        if summary.engaged:\n",
      "            # Estop plugged in and is ON, go to physically engaged\n",
      "            return EstopState.PHYSICALLY_ENGAGED\n",
      "        if summary.left_detected or summary.right_detected:\n",
      "            # Plugged in and NOT on, go to Disengaged\n",
      "            return EstopState.DISENGAGED\n",
      "        return EstopState.NOT_PRESENT\n",
      "\n",
      "    @staticmethod\n",
      "    def _transition_from_logically_engaged(summary: EstopSummary) -> EstopState:\n",
      "        if summary.engaged:\n",
      "            # Estop was turned on, go back to physically engaged\n",
      "            return EstopState.PHYSICALLY_ENGAGED\n",
      "        return EstopState.LOGICALLY_ENGAGED\n",
      "\n",
      "    def _emit_event(self, prev_state: EstopState) -> None:\n",
      "        \"\"\"Broadcast a state change to all listeners.\"\"\"\n",
      "        event = EstopStateNotification(old_state=prev_state, new_state=self._state)\n",
      "        for listener in self._listeners:\n",
      "            listener(event)\n",
      "\n",
      "    def METHOD_NAME(self, new_summary: EstopSummary) -> None:\n",
      "        \"\"\"Caches the new state summary and changes the _state variable.\"\"\"\n",
      "        self._summary = new_summary\n",
      "\n",
      "        prev_state = self._state\n",
      "\n",
      "        self._state = {\n",
      "            EstopState.PHYSICALLY_ENGAGED: self._transition_from_physically_engaged,\n",
      "            EstopState.DISENGAGED: self._transition_from_disengaged,\n",
      "            EstopState.NOT_PRESENT: self._transition_from_not_present,\n",
      "            EstopState.LOGICALLY_ENGAGED: self._transition_from_logically_engaged,\n",
      "        }[prev_state](new_summary)\n",
      "\n",
      "        if self._state != prev_state:\n",
      "            self._emit_event(prev_state=prev_state)\n",
      "\n",
      "    def get_physical_status(self, location: EstopAttachLocation) -> EstopPhysicalStatus:\n",
      "        \"\"\"Get the physical status of an attach location\"\"\"\n",
      "        detected = (\n",
      "            self._summary.left_detected\n",
      "            if location == EstopAttachLocation.LEFT\n",
      "            else self._summary.right_detected\n",
      "        )\n",
      "\n",
      "        if not detected:\n",
      "            return EstopPhysicalStatus.NOT_PRESENT\n",
      "        # Note that we actually *don't* have a way to check if an individual\n",
      "        # estop is activated or not. But we can return Engaged or Disengaged\n",
      "        # based on the global state.\n",
      "        return (\n",
      "            EstopPhysicalStatus.ENGAGED\n",
      "            if self._summary.engaged\n",
      "            else EstopPhysicalStatus.DISENGAGED\n",
      "        )\n",
      "\n",
      "    @property\n",
      "    def state(self) -> EstopState:\n",
      "        return self._state\n",
      "\n",
      "    def acknowledge_and_clear(self) -> EstopState:\n",
      "        \"\"\"Acknowledge a `logically_engaged` status if relevant.\n",
      "\n",
      "        If the current state is not LOGICALLY_ENGAGED, this does nothing.\n",
      "\n",
      "        If the current state *is* LOGICALLY_ENGAGED, this will move to the\n",
      "        correct return state (NOT_PRESENT or ENGAGED)\"\"\"\n",
      "        if self._state == EstopState.LOGICALLY_ENGAGED:\n",
      "            if self._summary.left_detected or self._summary.right_detected:\n",
      "                self._state = EstopState.DISENGAGED\n",
      "            else:\n",
      "                self._state = EstopState.NOT_PRESENT\n",
      "            self._emit_event(EstopState.LOGICALLY_ENGAGED)\n",
      "        return self._state\n",
      "====================\n",
      "\n",
      "get presets by operating system\n",
      "====================\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"The parser and parser plugin presets.\"\"\"\n",
      "\n",
      "import yaml\n",
      "\n",
      "from plaso.containers import artifacts\n",
      "from plaso.lib import errors\n",
      "from plaso.parsers import logger\n",
      "\n",
      "\n",
      "class ParserPreset(object):\n",
      "  \"\"\"Parser and parser plugin preset.\n",
      "\n",
      "  Attributes:\n",
      "    deprecated (bool): True if the preset is deprecated.\n",
      "    name (str): name of the preset.\n",
      "    operating_systems (list[OperatingSystemArtifact]): operating system\n",
      "        artifact attribute containers, that specify to which operating\n",
      "        systems the preset applies.\n",
      "    parsers (list[str]): names of parser and parser plugins.\n",
      "  \"\"\"\n",
      "\n",
      "  def __init__(self, name, parsers):\n",
      "    \"\"\"Initializes a parser and parser plugin preset.\n",
      "\n",
      "    Attributes:\n",
      "      name (str): name of the preset.\n",
      "      parsers (list[str]): names of parser and parser plugins.\n",
      "    \"\"\"\n",
      "    super(ParserPreset, self).__init__()\n",
      "    self.deprecated = False\n",
      "    self.name = name\n",
      "    self.operating_systems = []\n",
      "    self.parsers = parsers\n",
      "\n",
      "\n",
      "class ParserPresetsManager(object):\n",
      "  \"\"\"The parsers and plugin presets manager.\"\"\"\n",
      "\n",
      "  def __init__(self):\n",
      "    \"\"\"Initializes a parser and parser plugin presets manager.\"\"\"\n",
      "    super(ParserPresetsManager, self).__init__()\n",
      "    self._definitions = {}\n",
      "\n",
      "  def _ReadOperatingSystemArtifactValues(self, operating_system_values):\n",
      "    \"\"\"Reads an operating system artifact from a dictionary.\n",
      "\n",
      "    Args:\n",
      "      operating_system_values (dict[str, object]): operating system values.\n",
      "\n",
      "    Returns:\n",
      "      OperatingSystemArtifact: an operating system artifact attribute container.\n",
      "\n",
      "    Raises:\n",
      "      MalformedPresetError: if the format of the operating system values are\n",
      "          not set or incorrect.\n",
      "    \"\"\"\n",
      "    if not operating_system_values:\n",
      "      raise errors.MalformedPresetError('Missing operating system values.')\n",
      "\n",
      "    family = operating_system_values.get('family', None)\n",
      "    product = operating_system_values.get('product', None)\n",
      "    version = operating_system_values.get('version', None)\n",
      "\n",
      "    if not family and not product:\n",
      "      raise errors.MalformedPresetError(\n",
      "          'Invalid operating system missing family and product.')\n",
      "\n",
      "    return artifacts.OperatingSystemArtifact(\n",
      "        family=family, product=product, version=version)\n",
      "\n",
      "  def _ReadParserPresetValues(self, preset_definition_values):\n",
      "    \"\"\"Reads a parser preset from a dictionary.\n",
      "\n",
      "    Args:\n",
      "      preset_definition_values (dict[str, object]): preset definition values.\n",
      "\n",
      "    Returns:\n",
      "      ParserPreset: a parser preset.\n",
      "\n",
      "    Raises:\n",
      "      MalformedPresetError: if the format of the preset definition is not set\n",
      "          or incorrect, or the preset of a specific operating system has already\n",
      "          been set.\n",
      "    \"\"\"\n",
      "    if not preset_definition_values:\n",
      "      raise errors.MalformedPresetError('Missing preset definition values.')\n",
      "\n",
      "    name = preset_definition_values.get('name', None)\n",
      "    if not name:\n",
      "      raise errors.MalformedPresetError(\n",
      "          'Invalid preset definition missing name.')\n",
      "\n",
      "    parsers = preset_definition_values.get('parsers', None)\n",
      "    if not parsers:\n",
      "      raise errors.MalformedPresetError(\n",
      "          'Invalid preset definition missing parsers.')\n",
      "\n",
      "    parser_preset = ParserPreset(name, parsers)\n",
      "\n",
      "    parser_preset.deprecated = preset_definition_values.get('deprecated', False)\n",
      "\n",
      "    for operating_system_values in preset_definition_values.get(\n",
      "        'operating_systems', []):\n",
      "      operating_system = self._ReadOperatingSystemArtifactValues(\n",
      "          operating_system_values)\n",
      "      parser_preset.operating_systems.append(operating_system)\n",
      "\n",
      "    return parser_preset\n",
      "\n",
      "  def _ReadPresetsFromFileObject(self, file_object):\n",
      "    \"\"\"Reads parser and parser plugin presets from a file-like object.\n",
      "\n",
      "    Args:\n",
      "      file_object (file): file-like object containing the parser and parser\n",
      "          plugin presets definitions.\n",
      "\n",
      "    Yields:\n",
      "      ParserPreset: a parser preset.\n",
      "\n",
      "    Raises:\n",
      "      MalformedPresetError: if one or more plugin preset definitions are\n",
      "          malformed.\n",
      "    \"\"\"\n",
      "    yaml_generator = yaml.safe_load_all(file_object)\n",
      "\n",
      "    last_preset_definition = None\n",
      "    for yaml_definition in yaml_generator:\n",
      "      try:\n",
      "        preset_definition = self._ReadParserPresetValues(yaml_definition)\n",
      "      except errors.MalformedPresetError as exception:\n",
      "        error_location = 'At start'\n",
      "        if last_preset_definition:\n",
      "          error_location = 'After: {0:s}'.format(last_preset_definition.name)\n",
      "\n",
      "        raise errors.MalformedPresetError(\n",
      "            '{0:s} {1!s}'.format(error_location, exception))\n",
      "\n",
      "      yield preset_definition\n",
      "      last_preset_definition = preset_definition\n",
      "\n",
      "  def GetNames(self):\n",
      "    \"\"\"Retrieves the preset names.\n",
      "\n",
      "    Returns:\n",
      "      list[str]: preset names in alphabetical order.\n",
      "    \"\"\"\n",
      "    return sorted(self._definitions.keys())\n",
      "\n",
      "  def GetParsersByPreset(self, preset_name):\n",
      "    \"\"\"Retrieves the parser and plugin names of a specific preset.\n",
      "\n",
      "    Args:\n",
      "      preset_name (str): name of the preset.\n",
      "\n",
      "    Returns:\n",
      "      list[str]: parser and plugin names in alphabetical order.\n",
      "\n",
      "    Raises:\n",
      "      KeyError: if the preset does not exist.\n",
      "    \"\"\"\n",
      "    lookup_name = preset_name.lower()\n",
      "    preset_definition = self._definitions.get(lookup_name, None)\n",
      "    if preset_definition is None:\n",
      "      raise KeyError('Preset: {0:s} is not defined'.format(preset_name))\n",
      "\n",
      "    if preset_definition.deprecated:\n",
      "      logger.warning((\n",
      "          'Preset: {0:s} is deprecated and will be removed in a future '\n",
      "          'version').format(preset_name))\n",
      "\n",
      "    return sorted(preset_definition.parsers)\n",
      "\n",
      "  def GetPresetByName(self, name):\n",
      "    \"\"\"Retrieves a specific preset definition by name.\n",
      "\n",
      "    Args:\n",
      "      name (str): name of the preset.\n",
      "\n",
      "    Returns:\n",
      "      ParserPreset: a parser preset or None if not available.\n",
      "    \"\"\"\n",
      "    lookup_name = name.lower()\n",
      "    return self._definitions.get(lookup_name, None)\n",
      "\n",
      "  def METHOD_NAME(self, operating_system):\n",
      "    \"\"\"Retrieves preset definitions for a specific operating system.\n",
      "\n",
      "    Args:\n",
      "      operating_system (OperatingSystemArtifact): an operating system artifact\n",
      "          attribute container.\n",
      "\n",
      "    Returns:\n",
      "      list[PresetDefinition]: preset definition that correspond with the\n",
      "          operating system.\n",
      "    \"\"\"\n",
      "    preset_definitions = []\n",
      "    for preset_definition in self._definitions.values():\n",
      "      for preset_operating_system in preset_definition.operating_systems:\n",
      "        if preset_operating_system.IsEquivalent(operating_system):\n",
      "          preset_definitions.append(preset_definition)\n",
      "\n",
      "    return preset_definitions\n",
      "\n",
      "  def GetPresetsInformation(self):\n",
      "    \"\"\"Retrieves the presets information.\n",
      "\n",
      "    Returns:\n",
      "      list[tuple]: containing:\n",
      "\n",
      "        str: preset name.\n",
      "        str: comma separated parser and plugin names that are defined by\n",
      "            the preset.\n",
      "    \"\"\"\n",
      "    presets_information = []\n",
      "    for name, parser_preset in sorted(self._definitions.items()):\n",
      "      preset_information_tuple = (name, ', '.join(parser_preset.parsers))\n",
      "      # TODO: refactor to pass PresetDefinition.\n",
      "      presets_information.append(preset_information_tuple)\n",
      "\n",
      "    return presets_information\n",
      "\n",
      "  def ReadFromFile(self, path):\n",
      "    \"\"\"Reads parser and parser plugin presets from a file.\n",
      "\n",
      "    Args:\n",
      "      path (str): path of file that contains the the parser and parser plugin\n",
      "          presets configuration.\n",
      "\n",
      "    Raises:\n",
      "      MalformedPresetError: if one or more plugin preset definitions are\n",
      "          malformed.\n",
      "    \"\"\"\n",
      "    self._definitions = {}\n",
      "\n",
      "    with open(path, 'r', encoding='utf-8') as file_object:\n",
      "      for preset_definition in self._ReadPresetsFromFileObject(file_object):\n",
      "        self._definitions[preset_definition.name] = preset_definition\n",
      "====================\n",
      "\n",
      "predict\n",
      "====================\n",
      "import logging\n",
      "from time import time\n",
      "from typing import Any, Tuple\n",
      "\n",
      "import numpy as np\n",
      "import numpy.typing as npt\n",
      "from pandas import DataFrame\n",
      "\n",
      "from freqtrade.freqai.base_models.BasePyTorchModel import BasePyTorchModel\n",
      "from freqtrade.freqai.data_kitchen import FreqaiDataKitchen\n",
      "\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class BasePyTorchRegressor(BasePyTorchModel):\n",
      "    \"\"\"\n",
      "    A PyTorch implementation of a regressor.\n",
      "    User must implement fit method\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, **kwargs):\n",
      "        super().__init__(**kwargs)\n",
      "\n",
      "    def METHOD_NAME(\n",
      "        self, unfiltered_df: DataFrame, dk: FreqaiDataKitchen, **kwargs\n",
      "    ) -> Tuple[DataFrame, npt.NDArray[np.int_]]:\n",
      "        \"\"\"\n",
      "        Filter the prediction features data and predict with it.\n",
      "        :param unfiltered_df: Full dataframe for the current backtest period.\n",
      "        :return:\n",
      "        :pred_df: dataframe containing the predictions\n",
      "        :do_predict: np.array of 1s and 0s to indicate places where freqai needed to remove\n",
      "        data (NaNs) or felt uncertain about data (PCA and DI index)\n",
      "        \"\"\"\n",
      "\n",
      "        dk.find_features(unfiltered_df)\n",
      "        filtered_df, _ = dk.filter_features(\n",
      "            unfiltered_df, dk.training_features_list, training_filter=False\n",
      "        )\n",
      "        dk.data_dictionary[\"prediction_features\"] = filtered_df\n",
      "\n",
      "        dk.data_dictionary[\"prediction_features\"], outliers, _ = dk.feature_pipeline.transform(\n",
      "            dk.data_dictionary[\"prediction_features\"], outlier_check=True)\n",
      "\n",
      "        x = self.data_convertor.convert_x(\n",
      "            dk.data_dictionary[\"prediction_features\"],\n",
      "            device=self.device\n",
      "        )\n",
      "        self.model.model.eval()\n",
      "        y = self.model.model(x)\n",
      "        pred_df = DataFrame(y.detach().tolist(), columns=[dk.label_list[0]])\n",
      "        pred_df, _, _ = dk.label_pipeline.inverse_transform(pred_df)\n",
      "\n",
      "        if dk.feature_pipeline[\"di\"]:\n",
      "            dk.DI_values = dk.feature_pipeline[\"di\"].di_values\n",
      "        else:\n",
      "            dk.DI_values = np.zeros(outliers.shape[0])\n",
      "        dk.do_predict = outliers\n",
      "        return (pred_df, dk.do_predict)\n",
      "\n",
      "    def train(\n",
      "        self, unfiltered_df: DataFrame, pair: str, dk: FreqaiDataKitchen, **kwargs\n",
      "    ) -> Any:\n",
      "        \"\"\"\n",
      "        Filter the training data and train a model to it. Train makes heavy use of the datakitchen\n",
      "        for storing, saving, loading, and analyzing the data.\n",
      "        :param unfiltered_df: Full dataframe for the current training period\n",
      "        :return:\n",
      "        :model: Trained model which can be used to inference (self.predict)\n",
      "        \"\"\"\n",
      "\n",
      "        logger.info(f\"-------------------- Starting training {pair} --------------------\")\n",
      "\n",
      "        start_time = time()\n",
      "\n",
      "        features_filtered, labels_filtered = dk.filter_features(\n",
      "            unfiltered_df,\n",
      "            dk.training_features_list,\n",
      "            dk.label_list,\n",
      "            training_filter=True,\n",
      "        )\n",
      "\n",
      "        # split data into train/test data.\n",
      "        dd = dk.make_train_test_datasets(features_filtered, labels_filtered)\n",
      "        if not self.freqai_info.get(\"fit_live_predictions_candles\", 0) or not self.live:\n",
      "            dk.fit_labels()\n",
      "        dk.feature_pipeline = self.define_data_pipeline(threads=dk.thread_count)\n",
      "        dk.label_pipeline = self.define_label_pipeline(threads=dk.thread_count)\n",
      "\n",
      "        dd[\"train_labels\"], _, _ = dk.label_pipeline.fit_transform(dd[\"train_labels\"])\n",
      "        dd[\"test_labels\"], _, _ = dk.label_pipeline.transform(dd[\"test_labels\"])\n",
      "\n",
      "        (dd[\"train_features\"],\n",
      "         dd[\"train_labels\"],\n",
      "         dd[\"train_weights\"]) = dk.feature_pipeline.fit_transform(dd[\"train_features\"],\n",
      "                                                                  dd[\"train_labels\"],\n",
      "                                                                  dd[\"train_weights\"])\n",
      "        dd[\"train_labels\"], _, _ = dk.label_pipeline.fit_transform(dd[\"train_labels\"])\n",
      "\n",
      "        if self.freqai_info.get('data_split_parameters', {}).get('test_size', 0.1) != 0:\n",
      "            (dd[\"test_features\"],\n",
      "             dd[\"test_labels\"],\n",
      "             dd[\"test_weights\"]) = dk.feature_pipeline.transform(dd[\"test_features\"],\n",
      "                                                                 dd[\"test_labels\"],\n",
      "                                                                 dd[\"test_weights\"])\n",
      "            dd[\"test_labels\"], _, _ = dk.label_pipeline.transform(dd[\"test_labels\"])\n",
      "\n",
      "        logger.info(\n",
      "            f\"Training model on {len(dk.data_dictionary['train_features'].columns)} features\"\n",
      "        )\n",
      "        logger.info(f\"Training model on {len(dd['train_features'])} data points\")\n",
      "\n",
      "        model = self.fit(dd, dk)\n",
      "        end_time = time()\n",
      "\n",
      "        logger.info(f\"-------------------- Done training {pair} \"\n",
      "                    f\"({end_time - start_time:.2f} secs) --------------------\")\n",
      "\n",
      "        return model\n",
      "====================\n",
      "\n",
      "save optimizer\n",
      "====================\n",
      "from abc import ABC, abstractmethod\n",
      "from contextlib import nullcontext\n",
      "from typing import Any, List, Optional, Tuple, Union\n",
      "\n",
      "import numpy as np\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from coati.models.base import LM, Actor, Critic, RewardModel\n",
      "from coati.replay_buffer import ReplayBuffer\n",
      "from torch.optim import Optimizer\n",
      "from torch.utils.data import DataLoader\n",
      "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
      "\n",
      "from .sampler import DistributedSampler\n",
      "\n",
      "ModelOptimPair = Tuple[nn.Module, Optimizer]\n",
      "ModelOrModelOptimPair = Union[nn.Module, ModelOptimPair]\n",
      "\n",
      "\n",
      "class Strategy(ABC):\n",
      "    \"\"\"\n",
      "    Base class for training strategies.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        super().__init__()\n",
      "        self.setup_distributed()\n",
      "\n",
      "    @abstractmethod\n",
      "    def backward(\n",
      "        self, loss: torch.Tensor, model: nn.Module, optimizer: Optimizer, **kwargs\n",
      "    ) -> None:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def optimizer_step(self, optimizer: Optimizer, **kwargs) -> None:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def setup_distributed(self) -> None:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def setup_model(self, model: nn.Module) -> nn.Module:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def setup_optimizer(self, optimizer: Optimizer, model: nn.Module) -> Optimizer:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def setup_dataloader(\n",
      "        self, replay_buffer: ReplayBuffer, pin_memory: bool = False\n",
      "    ) -> DataLoader:\n",
      "        pass\n",
      "\n",
      "    def model_init_context(self):\n",
      "        return nullcontext()\n",
      "\n",
      "    def prepare(\n",
      "        self, *models_or_model_optim_pairs: ModelOrModelOptimPair\n",
      "    ) -> Union[List[ModelOrModelOptimPair], ModelOrModelOptimPair]:\n",
      "        \"\"\"Prepare models or model-optimizer-pairs based on each strategy.\n",
      "\n",
      "        Example::\n",
      "            >>> # when fine-tuning actor and critic\n",
      "            >>> (actor, actor_optim), (critic, critic_optim), reward_model, initial_model = strategy.prepare((actor, actor_optim), (critic, critic_optim), reward_model, initial_model)\n",
      "            >>> # or when training reward model\n",
      "            >>> (reward_model, reward_model_optim) = strategy.prepare((reward_model, reward_model_optim))\n",
      "            >>> # or just inference\n",
      "            >>> actor, critic = strategy.prepare(actor, critic)\n",
      "\n",
      "        Returns:\n",
      "            Union[List[ModelOrModelOptimPair], ModelOrModelOptimPair]: Models or model-optimizer-pairs in the original order.\n",
      "        \"\"\"\n",
      "\n",
      "        def prepare_model(model: nn.Module):\n",
      "            if isinstance(model, Actor):\n",
      "                return Actor(self.setup_model(self._unwrap_model(model)))\n",
      "            return self.setup_model(self._unwrap_model(model))\n",
      "\n",
      "        rets = []\n",
      "        for arg in models_or_model_optim_pairs:\n",
      "            if isinstance(arg, tuple):\n",
      "                assert (\n",
      "                    len(arg) == 2\n",
      "                ), f'Expect (model, optimizer) pair, got a tuple with size \"{len(arg)}\"'\n",
      "                model, optimizer = arg\n",
      "                model = prepare_model(model)\n",
      "                optimizer = self.setup_optimizer(optimizer, self._unwrap_model(model))\n",
      "                rets.append((model, optimizer))\n",
      "            elif isinstance(arg, nn.Module):\n",
      "                rets.append(prepare_model(arg))\n",
      "            else:\n",
      "                raise RuntimeError(\n",
      "                    f\"Expect model or (model, optimizer) pair, got {type(arg)}\"\n",
      "                )\n",
      "\n",
      "        if len(rets) == 1:\n",
      "            return rets[0]\n",
      "        return rets\n",
      "\n",
      "    @staticmethod\n",
      "    def _unwrap_model(model: nn.Module) -> nn.Module:\n",
      "        \"\"\"Useful for saving state dict. As actor is wrapped by Actor class again in `prepare()`, we should unwrap it before saving.\n",
      "\n",
      "        Args:\n",
      "            model (nn.Module): an actor or a critic\n",
      "        \"\"\"\n",
      "        if isinstance(model, Actor) or isinstance(model, LM):\n",
      "            return model.model\n",
      "        return model\n",
      "\n",
      "    @staticmethod\n",
      "    def _unwrap_actor(actor: Actor) -> nn.Module:\n",
      "        \"\"\"Get `actor.model` from a wrapped (by `prepare()`) actor. Useful for getting original huggingface model.\n",
      "\n",
      "        Args:\n",
      "            actor (Actor): a wrapped actor\n",
      "        \"\"\"\n",
      "        return Strategy._unwrap_model(actor)\n",
      "\n",
      "    @abstractmethod\n",
      "    def save_model(\n",
      "        self,\n",
      "        model: nn.Module,\n",
      "        path: str,\n",
      "        only_rank0: bool = False,\n",
      "        tokenizer: Optional[PreTrainedTokenizerBase] = None,\n",
      "    ) -> None:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def load_model(\n",
      "        self, model: nn.Module, path: str, map_location: Any = None, strict: bool = True\n",
      "    ) -> None:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def METHOD_NAME(\n",
      "        self, optimizer: Optimizer, path: str, only_rank0: bool = False\n",
      "    ) -> None:\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def load_optimizer(\n",
      "        self, optimizer: Optimizer, path: str, map_location: Any = None\n",
      "    ) -> None:\n",
      "        pass\n",
      "\n",
      "    def setup_sampler(self, dataset) -> DistributedSampler:\n",
      "        return DistributedSampler(dataset, 1, 0)\n",
      "====================\n",
      "\n",
      "validate organization\n",
      "====================\n",
      "# coding=utf-8\n",
      "# --------------------------------------------------------------------------\n",
      "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
      "# Licensed under the MIT License. See License.txt in the project root for license information.\n",
      "# Code generated by Microsoft (R) AutoRest Code Generator.\n",
      "# Changes may cause incorrect behavior and will be lost if the code is regenerated.\n",
      "# --------------------------------------------------------------------------\n",
      "from typing import TYPE_CHECKING\n",
      "import warnings\n",
      "\n",
      "from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error\n",
      "from azure.core.pipeline import PipelineResponse\n",
      "from azure.core.pipeline.transport import HttpRequest, HttpResponse\n",
      "from azure.mgmt.core.exceptions import ARMErrorFormat\n",
      "\n",
      "from .. import models\n",
      "\n",
      "if TYPE_CHECKING:\n",
      "    # pylint: disable=unused-import,ungrouped-imports\n",
      "    from typing import Any, Callable, Dict, Generic, Optional, TypeVar\n",
      "\n",
      "    T = TypeVar('T')\n",
      "    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]\n",
      "\n",
      "class ValidationsOperations(object):\n",
      "    \"\"\"ValidationsOperations operations.\n",
      "\n",
      "    You should not instantiate this class directly. Instead, you should create a Client instance that\n",
      "    instantiates it for you and attaches it as an attribute.\n",
      "\n",
      "    :ivar models: Alias to model classes used in this operation group.\n",
      "    :type models: ~azure.mgmt.confluent.models\n",
      "    :param client: Client for service requests.\n",
      "    :param config: Configuration of service client.\n",
      "    :param serializer: An object model serializer.\n",
      "    :param deserializer: An object model deserializer.\n",
      "    \"\"\"\n",
      "\n",
      "    models = models\n",
      "\n",
      "    def __init__(self, client, config, serializer, deserializer):\n",
      "        self._client = client\n",
      "        self._serialize = serializer\n",
      "        self._deserialize = deserializer\n",
      "        self._config = config\n",
      "\n",
      "    def METHOD_NAME(\n",
      "        self,\n",
      "        resource_group_name,  # type: str\n",
      "        organization_name,  # type: str\n",
      "        body,  # type: \"models.OrganizationResource\"\n",
      "        **kwargs  # type: Any\n",
      "    ):\n",
      "        # type: (...) -> \"models.OrganizationResource\"\n",
      "        \"\"\"Organization Validate proxy resource.\n",
      "\n",
      "        Organization Validate proxy resource.\n",
      "\n",
      "        :param resource_group_name: Resource group name.\n",
      "        :type resource_group_name: str\n",
      "        :param organization_name: Organization resource name.\n",
      "        :type organization_name: str\n",
      "        :param body: Organization resource model.\n",
      "        :type body: ~azure.mgmt.confluent.models.OrganizationResource\n",
      "        :keyword callable cls: A custom type or function that will be passed the direct response\n",
      "        :return: OrganizationResource, or the result of cls(response)\n",
      "        :rtype: ~azure.mgmt.confluent.models.OrganizationResource\n",
      "        :raises: ~azure.core.exceptions.HttpResponseError\n",
      "        \"\"\"\n",
      "        cls = kwargs.pop('cls', None)  # type: ClsType[\"models.OrganizationResource\"]\n",
      "        error_map = {\n",
      "            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError\n",
      "        }\n",
      "        error_map.update(kwargs.pop('error_map', {}))\n",
      "        api_version = \"2021-03-01-preview\"\n",
      "        content_type = kwargs.pop(\"content_type\", \"application/json\")\n",
      "        accept = \"application/json\"\n",
      "\n",
      "        # Construct URL\n",
      "        url = self.METHOD_NAME.metadata['url']  # type: ignore\n",
      "        path_format_arguments = {\n",
      "            'subscriptionId': self._serialize.url(\"self._config.subscription_id\", self._config.subscription_id, 'str'),\n",
      "            'resourceGroupName': self._serialize.url(\"resource_group_name\", resource_group_name, 'str'),\n",
      "            'organizationName': self._serialize.url(\"organization_name\", organization_name, 'str'),\n",
      "        }\n",
      "        url = self._client.format_url(url, **path_format_arguments)\n",
      "\n",
      "        # Construct parameters\n",
      "        query_parameters = {}  # type: Dict[str, Any]\n",
      "        query_parameters['api-version'] = self._serialize.query(\"api_version\", api_version, 'str')\n",
      "\n",
      "        # Construct headers\n",
      "        header_parameters = {}  # type: Dict[str, Any]\n",
      "        header_parameters['Content-Type'] = self._serialize.header(\"content_type\", content_type, 'str')\n",
      "        header_parameters['Accept'] = self._serialize.header(\"accept\", accept, 'str')\n",
      "\n",
      "        body_content_kwargs = {}  # type: Dict[str, Any]\n",
      "        body_content = self._serialize.body(body, 'OrganizationResource')\n",
      "        body_content_kwargs['content'] = body_content\n",
      "        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)\n",
      "        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)\n",
      "        response = pipeline_response.http_response\n",
      "\n",
      "        if response.status_code not in [200]:\n",
      "            map_error(status_code=response.status_code, response=response, error_map=error_map)\n",
      "            error = self._deserialize(models.ResourceProviderDefaultErrorResponse, response)\n",
      "            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)\n",
      "\n",
      "        deserialized = self._deserialize('OrganizationResource', pipeline_response)\n",
      "\n",
      "        if cls:\n",
      "            return cls(pipeline_response, deserialized, {})\n",
      "\n",
      "        return deserialized\n",
      "    METHOD_NAME.metadata = {'url': '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Confluent/validations/{organizationName}/orgvalidate'}  # type: ignore\n",
      "====================\n",
      "\n",
      "get permission binding output\n",
      "====================\n",
      "# coding=utf-8\n",
      "# *** WARNING: this file was generated by pulumi. ***\n",
      "# *** Do not edit by hand unless you're certain you know what you are doing! ***\n",
      "\n",
      "import copy\n",
      "import warnings\n",
      "import pulumi\n",
      "import pulumi.runtime\n",
      "from typing import Any, Mapping, Optional, Sequence, Union, overload\n",
      "from .. import _utilities\n",
      "from . import outputs\n",
      "\n",
      "__all__ = [\n",
      "    'GetPermissionBindingResult',\n",
      "    'AwaitableGetPermissionBindingResult',\n",
      "    'get_permission_binding',\n",
      "    'get_permission_binding_output',\n",
      "]\n",
      "\n",
      "@pulumi.output_type\n",
      "class GetPermissionBindingResult:\n",
      "    \"\"\"\n",
      "    The Permission binding resource.\n",
      "    \"\"\"\n",
      "    def __init__(__self__, client_group_name=None, description=None, id=None, name=None, permission=None, provisioning_state=None, system_data=None, topic_space_name=None, type=None):\n",
      "        if client_group_name and not isinstance(client_group_name, str):\n",
      "            raise TypeError(\"Expected argument 'client_group_name' to be a str\")\n",
      "        pulumi.set(__self__, \"client_group_name\", client_group_name)\n",
      "        if description and not isinstance(description, str):\n",
      "            raise TypeError(\"Expected argument 'description' to be a str\")\n",
      "        pulumi.set(__self__, \"description\", description)\n",
      "        if id and not isinstance(id, str):\n",
      "            raise TypeError(\"Expected argument 'id' to be a str\")\n",
      "        pulumi.set(__self__, \"id\", id)\n",
      "        if name and not isinstance(name, str):\n",
      "            raise TypeError(\"Expected argument 'name' to be a str\")\n",
      "        pulumi.set(__self__, \"name\", name)\n",
      "        if permission and not isinstance(permission, str):\n",
      "            raise TypeError(\"Expected argument 'permission' to be a str\")\n",
      "        pulumi.set(__self__, \"permission\", permission)\n",
      "        if provisioning_state and not isinstance(provisioning_state, str):\n",
      "            raise TypeError(\"Expected argument 'provisioning_state' to be a str\")\n",
      "        pulumi.set(__self__, \"provisioning_state\", provisioning_state)\n",
      "        if system_data and not isinstance(system_data, dict):\n",
      "            raise TypeError(\"Expected argument 'system_data' to be a dict\")\n",
      "        pulumi.set(__self__, \"system_data\", system_data)\n",
      "        if topic_space_name and not isinstance(topic_space_name, str):\n",
      "            raise TypeError(\"Expected argument 'topic_space_name' to be a str\")\n",
      "        pulumi.set(__self__, \"topic_space_name\", topic_space_name)\n",
      "        if type and not isinstance(type, str):\n",
      "            raise TypeError(\"Expected argument 'type' to be a str\")\n",
      "        pulumi.set(__self__, \"type\", type)\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter(name=\"clientGroupName\")\n",
      "    def client_group_name(self) -> Optional[str]:\n",
      "        \"\"\"\n",
      "        The name of the client group resource that the permission is bound to.\n",
      "        The client group needs to be a resource under the same namespace the permission binding is a part of.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"client_group_name\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter\n",
      "    def description(self) -> Optional[str]:\n",
      "        \"\"\"\n",
      "        Description for the Permission Binding resource.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"description\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter\n",
      "    def id(self) -> str:\n",
      "        \"\"\"\n",
      "        Fully qualified identifier of the resource.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"id\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter\n",
      "    def name(self) -> str:\n",
      "        \"\"\"\n",
      "        Name of the resource.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"name\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter\n",
      "    def permission(self) -> Optional[str]:\n",
      "        \"\"\"\n",
      "        The allowed permission.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"permission\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter(name=\"provisioningState\")\n",
      "    def provisioning_state(self) -> str:\n",
      "        \"\"\"\n",
      "        Provisioning state of the PermissionBinding resource.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"provisioning_state\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter(name=\"systemData\")\n",
      "    def system_data(self) -> 'outputs.SystemDataResponse':\n",
      "        \"\"\"\n",
      "        The system metadata relating to the PermissionBinding resource.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"system_data\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter(name=\"topicSpaceName\")\n",
      "    def topic_space_name(self) -> Optional[str]:\n",
      "        \"\"\"\n",
      "        The name of the Topic Space resource that the permission is bound to.\n",
      "        The Topic space needs to be a resource under the same namespace the permission binding is a part of.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"topic_space_name\")\n",
      "\n",
      "    @property\n",
      "    @pulumi.getter\n",
      "    def type(self) -> str:\n",
      "        \"\"\"\n",
      "        Type of the resource.\n",
      "        \"\"\"\n",
      "        return pulumi.get(self, \"type\")\n",
      "\n",
      "\n",
      "class AwaitableGetPermissionBindingResult(GetPermissionBindingResult):\n",
      "    # pylint: disable=using-constant-test\n",
      "    def __await__(self):\n",
      "        if False:\n",
      "            yield self\n",
      "        return GetPermissionBindingResult(\n",
      "            client_group_name=self.client_group_name,\n",
      "            description=self.description,\n",
      "            id=self.id,\n",
      "            name=self.name,\n",
      "            permission=self.permission,\n",
      "            provisioning_state=self.provisioning_state,\n",
      "            system_data=self.system_data,\n",
      "            topic_space_name=self.topic_space_name,\n",
      "            type=self.type)\n",
      "\n",
      "\n",
      "def get_permission_binding(namespace_name: Optional[str] = None,\n",
      "                           permission_binding_name: Optional[str] = None,\n",
      "                           resource_group_name: Optional[str] = None,\n",
      "                           opts: Optional[pulumi.InvokeOptions] = None) -> AwaitableGetPermissionBindingResult:\n",
      "    \"\"\"\n",
      "    Get properties of a permission binding.\n",
      "    Azure REST API version: 2023-06-01-preview.\n",
      "\n",
      "\n",
      "    :param str namespace_name: Name of the namespace.\n",
      "    :param str permission_binding_name: Name of the permission binding.\n",
      "    :param str resource_group_name: The name of the resource group within the user's subscription.\n",
      "    \"\"\"\n",
      "    __args__ = dict()\n",
      "    __args__['namespaceName'] = namespace_name\n",
      "    __args__['permissionBindingName'] = permission_binding_name\n",
      "    __args__['resourceGroupName'] = resource_group_name\n",
      "    opts = pulumi.InvokeOptions.merge(_utilities.get_invoke_opts_defaults(), opts)\n",
      "    __ret__ = pulumi.runtime.invoke('azure-native:eventgrid:getPermissionBinding', __args__, opts=opts, typ=GetPermissionBindingResult).value\n",
      "\n",
      "    return AwaitableGetPermissionBindingResult(\n",
      "        client_group_name=pulumi.get(__ret__, 'client_group_name'),\n",
      "        description=pulumi.get(__ret__, 'description'),\n",
      "        id=pulumi.get(__ret__, 'id'),\n",
      "        name=pulumi.get(__ret__, 'name'),\n",
      "        permission=pulumi.get(__ret__, 'permission'),\n",
      "        provisioning_state=pulumi.get(__ret__, 'provisioning_state'),\n",
      "        system_data=pulumi.get(__ret__, 'system_data'),\n",
      "        topic_space_name=pulumi.get(__ret__, 'topic_space_name'),\n",
      "        type=pulumi.get(__ret__, 'type'))\n",
      "\n",
      "\n",
      "@_utilities.lift_output_func(get_permission_binding)\n",
      "def METHOD_NAME(namespace_name: Optional[pulumi.Input[str]] = None,\n",
      "                                  permission_binding_name: Optional[pulumi.Input[str]] = None,\n",
      "                                  resource_group_name: Optional[pulumi.Input[str]] = None,\n",
      "                                  opts: Optional[pulumi.InvokeOptions] = None) -> pulumi.Output[GetPermissionBindingResult]:\n",
      "    \"\"\"\n",
      "    Get properties of a permission binding.\n",
      "    Azure REST API version: 2023-06-01-preview.\n",
      "\n",
      "\n",
      "    :param str namespace_name: Name of the namespace.\n",
      "    :param str permission_binding_name: Name of the permission binding.\n",
      "    :param str resource_group_name: The name of the resource group within the user's subscription.\n",
      "    \"\"\"\n",
      "    ...\n",
      "====================\n",
      "\n",
      "show idle about\n",
      "====================\n",
      "\"\"\"About Dialog for IDLE\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "from sys import version\n",
      "from tkinter import *\n",
      "from idlelib import textView\n",
      "\n",
      "class AboutDialog(Toplevel):\n",
      "    \"\"\"Modal about dialog for idle\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, parent, title, _htest=False):\n",
      "        \"\"\"\n",
      "        _htest - bool, change box location when running htest\n",
      "        \"\"\"\n",
      "        Toplevel.__init__(self, parent)\n",
      "        self.configure(borderwidth=5)\n",
      "        # place dialog below parent if running htest\n",
      "        self.geometry(\"+%d+%d\" % (\n",
      "                        parent.winfo_rootx()+30,\n",
      "                        parent.winfo_rooty()+(30 if not _htest else 100)))\n",
      "        self.bg = \"#707070\"\n",
      "        self.fg = \"#ffffff\"\n",
      "        self.CreateWidgets()\n",
      "        self.resizable(height=FALSE, width=FALSE)\n",
      "        self.title(title)\n",
      "        self.transient(parent)\n",
      "        self.grab_set()\n",
      "        self.protocol(\"WM_DELETE_WINDOW\", self.Ok)\n",
      "        self.parent = parent\n",
      "        self.buttonOk.focus_set()\n",
      "        self.bind('<Return>',self.Ok) #dismiss dialog\n",
      "        self.bind('<Escape>',self.Ok) #dismiss dialog\n",
      "        self.wait_window()\n",
      "\n",
      "    def CreateWidgets(self):\n",
      "        release = version[:version.index(' ')]\n",
      "        frameMain = Frame(self, borderwidth=2, relief=SUNKEN)\n",
      "        frameButtons = Frame(self)\n",
      "        frameButtons.pack(side=BOTTOM, fill=X)\n",
      "        frameMain.pack(side=TOP, expand=TRUE, fill=BOTH)\n",
      "        self.buttonOk = Button(frameButtons, text='Close',\n",
      "                               command=self.Ok)\n",
      "        self.buttonOk.pack(padx=5, pady=5)\n",
      "        #self.picture = Image('photo', data=self.pictureData)\n",
      "        frameBg = Frame(frameMain, bg=self.bg)\n",
      "        frameBg.pack(expand=TRUE, fill=BOTH)\n",
      "        labelTitle = Label(frameBg, text='IDLE', fg=self.fg, bg=self.bg,\n",
      "                           font=('courier', 24, 'bold'))\n",
      "        labelTitle.grid(row=0, column=0, sticky=W, padx=10, pady=10)\n",
      "        #labelPicture = Label(frameBg, text='[picture]')\n",
      "        #image=self.picture, bg=self.bg)\n",
      "        #labelPicture.grid(row=1, column=1, sticky=W, rowspan=2,\n",
      "        #                  padx=0, pady=3)\n",
      "        byline = \"Python's Integrated DeveLopment Environment\" + 5*'\\n'\n",
      "        labelDesc = Label(frameBg, text=byline, justify=LEFT,\n",
      "                          fg=self.fg, bg=self.bg)\n",
      "        labelDesc.grid(row=2, column=0, sticky=W, columnspan=3, padx=10, pady=5)\n",
      "        labelEmail = Label(frameBg, text='email:  idle-dev@python.org',\n",
      "                           justify=LEFT, fg=self.fg, bg=self.bg)\n",
      "        labelEmail.grid(row=6, column=0, columnspan=2,\n",
      "                        sticky=W, padx=10, pady=0)\n",
      "        labelWWW = Label(frameBg, text='https://docs.python.org/' +\n",
      "                         version[:3] + '/library/idle.html',\n",
      "                         justify=LEFT, fg=self.fg, bg=self.bg)\n",
      "        labelWWW.grid(row=7, column=0, columnspan=2, sticky=W, padx=10, pady=0)\n",
      "        Frame(frameBg, borderwidth=1, relief=SUNKEN,\n",
      "              height=2, bg=self.bg).grid(row=8, column=0, sticky=EW,\n",
      "                                         columnspan=3, padx=5, pady=5)\n",
      "        labelPythonVer = Label(frameBg, text='Python version:  ' +\n",
      "                               release, fg=self.fg, bg=self.bg)\n",
      "        labelPythonVer.grid(row=9, column=0, sticky=W, padx=10, pady=0)\n",
      "        tkVer = self.tk.call('info', 'patchlevel')\n",
      "        labelTkVer = Label(frameBg, text='Tk version:  '+\n",
      "                           tkVer, fg=self.fg, bg=self.bg)\n",
      "        labelTkVer.grid(row=9, column=1, sticky=W, padx=2, pady=0)\n",
      "        py_button_f = Frame(frameBg, bg=self.bg)\n",
      "        py_button_f.grid(row=10, column=0, columnspan=2, sticky=NSEW)\n",
      "        buttonLicense = Button(py_button_f, text='License', width=8,\n",
      "                               highlightbackground=self.bg,\n",
      "                               command=self.ShowLicense)\n",
      "        buttonLicense.pack(side=LEFT, padx=10, pady=10)\n",
      "        buttonCopyright = Button(py_button_f, text='Copyright', width=8,\n",
      "                                 highlightbackground=self.bg,\n",
      "                                 command=self.ShowCopyright)\n",
      "        buttonCopyright.pack(side=LEFT, padx=10, pady=10)\n",
      "        buttonCredits = Button(py_button_f, text='Credits', width=8,\n",
      "                               highlightbackground=self.bg,\n",
      "                               command=self.ShowPythonCredits)\n",
      "        buttonCredits.pack(side=LEFT, padx=10, pady=10)\n",
      "        Frame(frameBg, borderwidth=1, relief=SUNKEN,\n",
      "              height=2, bg=self.bg).grid(row=11, column=0, sticky=EW,\n",
      "                                         columnspan=3, padx=5, pady=5)\n",
      "        idle_v = Label(frameBg, text='IDLE version:   ' + release,\n",
      "                       fg=self.fg, bg=self.bg)\n",
      "        idle_v.grid(row=12, column=0, sticky=W, padx=10, pady=0)\n",
      "        idle_button_f = Frame(frameBg, bg=self.bg)\n",
      "        idle_button_f.grid(row=13, column=0, columnspan=3, sticky=NSEW)\n",
      "        idle_about_b = Button(idle_button_f, text='README', width=8,\n",
      "                                highlightbackground=self.bg,\n",
      "                                command=self.METHOD_NAME)\n",
      "        idle_about_b.pack(side=LEFT, padx=10, pady=10)\n",
      "        idle_news_b = Button(idle_button_f, text='NEWS', width=8,\n",
      "                                highlightbackground=self.bg,\n",
      "                                command=self.ShowIDLENEWS)\n",
      "        idle_news_b.pack(side=LEFT, padx=10, pady=10)\n",
      "        idle_credits_b = Button(idle_button_f, text='Credits', width=8,\n",
      "                                highlightbackground=self.bg,\n",
      "                                command=self.ShowIDLECredits)\n",
      "        idle_credits_b.pack(side=LEFT, padx=10, pady=10)\n",
      "\n",
      "    def ShowLicense(self):\n",
      "        self.display_printer_text('About - License', license)\n",
      "\n",
      "    def ShowCopyright(self):\n",
      "        self.display_printer_text('About - Copyright', copyright)\n",
      "\n",
      "    def ShowPythonCredits(self):\n",
      "        self.display_printer_text('About - Python Credits', credits)\n",
      "\n",
      "    def ShowIDLECredits(self):\n",
      "        self.display_file_text('About - Credits', 'CREDITS.txt', 'iso-8859-1')\n",
      "\n",
      "    def METHOD_NAME(self):\n",
      "        self.display_file_text('About - Readme', 'README.txt')\n",
      "\n",
      "    def ShowIDLENEWS(self):\n",
      "        self.display_file_text('About - NEWS', 'NEWS.txt')\n",
      "\n",
      "    def display_printer_text(self, title, printer):\n",
      "        printer._Printer__setup()\n",
      "        text = '\\n'.join(printer._Printer__lines)\n",
      "        textView.view_text(self, title, text)\n",
      "\n",
      "    def display_file_text(self, title, filename, encoding=None):\n",
      "        fn = os.path.join(os.path.abspath(os.path.dirname(__file__)), filename)\n",
      "        textView.view_file(self, title, fn, encoding)\n",
      "\n",
      "    def Ok(self, event=None):\n",
      "        self.destroy()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    from idlelib.idle_test.htest import run\n",
      "    run(AboutDialog)\n",
      "====================\n",
      "\n",
      "build list request\n",
      "====================\n",
      "# pylint: disable=too-many-lines\n",
      "# coding=utf-8\n",
      "# --------------------------------------------------------------------------\n",
      "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
      "# Licensed under the MIT License. See License.txt in the project root for license information.\n",
      "# Code generated by Microsoft (R) AutoRest Code Generator.\n",
      "# Changes may cause incorrect behavior and will be lost if the code is regenerated.\n",
      "# --------------------------------------------------------------------------\n",
      "from typing import Any, Callable, Dict, Iterable, Optional, TypeVar\n",
      "\n",
      "from azure.core.exceptions import (\n",
      "    ClientAuthenticationError,\n",
      "    HttpResponseError,\n",
      "    ResourceExistsError,\n",
      "    ResourceNotFoundError,\n",
      "    ResourceNotModifiedError,\n",
      "    map_error,\n",
      ")\n",
      "from azure.core.paging import ItemPaged\n",
      "from azure.core.pipeline import PipelineResponse\n",
      "from azure.core.pipeline.transport import HttpResponse\n",
      "from azure.core.rest import HttpRequest\n",
      "from azure.core.tracing.decorator import distributed_trace\n",
      "from azure.core.utils import case_insensitive_dict\n",
      "from azure.mgmt.core.exceptions import ARMErrorFormat\n",
      "\n",
      "from .. import models as _models\n",
      "from .._serialization import Serializer\n",
      "from .._vendor import MixinABC, _convert_request\n",
      "\n",
      "T = TypeVar(\"T\")\n",
      "ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]\n",
      "\n",
      "_SERIALIZER = Serializer()\n",
      "_SERIALIZER.client_side_validation = False\n",
      "\n",
      "\n",
      "def METHOD_NAME(**kwargs: Any) -> HttpRequest:\n",
      "    _headers = case_insensitive_dict(kwargs.pop(\"headers\", {}) or {})\n",
      "    _params = case_insensitive_dict(kwargs.pop(\"params\", {}) or {})\n",
      "\n",
      "    api_version = kwargs.pop(\"api_version\", _params.pop(\"api-version\", \"2022-03-01\"))  # type: str\n",
      "    accept = _headers.pop(\"Accept\", \"application/json\")\n",
      "\n",
      "    # Construct URL\n",
      "    _url = kwargs.pop(\"template_url\", \"/providers/Microsoft.Capacity/operations\")\n",
      "\n",
      "    # Construct parameters\n",
      "    _params[\"api-version\"] = _SERIALIZER.query(\"api_version\", api_version, \"str\")\n",
      "\n",
      "    # Construct headers\n",
      "    _headers[\"Accept\"] = _SERIALIZER.header(\"accept\", accept, \"str\")\n",
      "\n",
      "    return HttpRequest(method=\"GET\", url=_url, params=_params, headers=_headers, **kwargs)\n",
      "\n",
      "\n",
      "class OperationOperations:\n",
      "    \"\"\"\n",
      "    .. warning::\n",
      "        **DO NOT** instantiate this class directly.\n",
      "\n",
      "        Instead, you should access the following operations through\n",
      "        :class:`~azure.mgmt.reservations.AzureReservationAPI`'s\n",
      "        :attr:`operation` attribute.\n",
      "    \"\"\"\n",
      "\n",
      "    models = _models\n",
      "\n",
      "    def __init__(self, *args, **kwargs):\n",
      "        input_args = list(args)\n",
      "        self._client = input_args.pop(0) if input_args else kwargs.pop(\"client\")\n",
      "        self._config = input_args.pop(0) if input_args else kwargs.pop(\"config\")\n",
      "        self._serialize = input_args.pop(0) if input_args else kwargs.pop(\"serializer\")\n",
      "        self._deserialize = input_args.pop(0) if input_args else kwargs.pop(\"deserializer\")\n",
      "\n",
      "    @distributed_trace\n",
      "    def list(self, **kwargs: Any) -> Iterable[\"_models.OperationResponse\"]:\n",
      "        \"\"\"Get operations.\n",
      "\n",
      "        List all the operations.\n",
      "\n",
      "        :keyword callable cls: A custom type or function that will be passed the direct response\n",
      "        :return: An iterator like instance of either OperationResponse or the result of cls(response)\n",
      "        :rtype: ~azure.core.paging.ItemPaged[~azure.mgmt.reservations.models.OperationResponse]\n",
      "        :raises ~azure.core.exceptions.HttpResponseError:\n",
      "        \"\"\"\n",
      "        _headers = kwargs.pop(\"headers\", {}) or {}\n",
      "        _params = case_insensitive_dict(kwargs.pop(\"params\", {}) or {})\n",
      "\n",
      "        api_version = kwargs.pop(\"api_version\", _params.pop(\"api-version\", \"2022-03-01\"))  # type: str\n",
      "        cls = kwargs.pop(\"cls\", None)  # type: ClsType[_models.OperationList]\n",
      "\n",
      "        error_map = {\n",
      "            401: ClientAuthenticationError,\n",
      "            404: ResourceNotFoundError,\n",
      "            409: ResourceExistsError,\n",
      "            304: ResourceNotModifiedError,\n",
      "        }\n",
      "        error_map.update(kwargs.pop(\"error_map\", {}) or {})\n",
      "\n",
      "        def prepare_request(next_link=None):\n",
      "            if not next_link:\n",
      "\n",
      "                request = METHOD_NAME(\n",
      "                    api_version=api_version,\n",
      "                    template_url=self.list.metadata[\"url\"],\n",
      "                    headers=_headers,\n",
      "                    params=_params,\n",
      "                )\n",
      "                request = _convert_request(request)\n",
      "                request.url = self._client.format_url(request.url)  # type: ignore\n",
      "\n",
      "            else:\n",
      "                request = HttpRequest(\"GET\", next_link)\n",
      "                request = _convert_request(request)\n",
      "                request.url = self._client.format_url(request.url)  # type: ignore\n",
      "                request.method = \"GET\"\n",
      "            return request\n",
      "\n",
      "        def extract_data(pipeline_response):\n",
      "            deserialized = self._deserialize(\"OperationList\", pipeline_response)\n",
      "            list_of_elem = deserialized.value\n",
      "            if cls:\n",
      "                list_of_elem = cls(list_of_elem)\n",
      "            return deserialized.next_link or None, iter(list_of_elem)\n",
      "\n",
      "        def get_next(next_link=None):\n",
      "            request = prepare_request(next_link)\n",
      "\n",
      "            pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access\n",
      "                request, stream=False, **kwargs\n",
      "            )\n",
      "            response = pipeline_response.http_response\n",
      "\n",
      "            if response.status_code not in [200]:\n",
      "                map_error(status_code=response.status_code, response=response, error_map=error_map)\n",
      "                error = self._deserialize.failsafe_deserialize(_models.Error, pipeline_response)\n",
      "                raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)\n",
      "\n",
      "            return pipeline_response\n",
      "\n",
      "        return ItemPaged(get_next, extract_data)\n",
      "\n",
      "    list.metadata = {\"url\": \"/providers/Microsoft.Capacity/operations\"}  # type: ignore\n",
      "====================\n",
      "\n",
      "test serialize\n",
      "====================\n",
      "import json\n",
      "from datetime import datetime, timezone\n",
      "from unittest import TestCase\n",
      "\n",
      "from ......messaging.decorators.attach_decorator import AttachDecorator\n",
      "from ......messaging.util import str_to_epoch\n",
      "\n",
      "from .....didcomm_prefix import DIDCommPrefix\n",
      "\n",
      "from ...message_types import ATTACH_DECO_IDS, PRESENTATION_REQUEST\n",
      "\n",
      "from ..presentation_request import PresentationRequest\n",
      "\n",
      "\n",
      "NOW_8601 = datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(\" \", \"seconds\")\n",
      "NOW_EPOCH = str_to_epoch(NOW_8601)\n",
      "CD_ID = \"GMm4vMw8LLrLJjp81kRRLp:3:CL:12:tag\"\n",
      "INDY_PROOF_REQ = json.loads(\n",
      "    f\"\"\"{{\n",
      "    \"name\": \"proof-req\",\n",
      "    \"version\": \"1.0\",\n",
      "    \"nonce\": \"12345\",\n",
      "    \"requested_attributes\": {{\n",
      "        \"0_player_uuid\": {{\n",
      "            \"name\": \"player\",\n",
      "            \"restrictions\": [\n",
      "                {{\n",
      "                    \"cred_def_id\": \"{CD_ID}\"\n",
      "                }}\n",
      "            ],\n",
      "            \"non_revoked\": {{\n",
      "                \"from\": {NOW_EPOCH},\n",
      "                \"to\": {NOW_EPOCH}\n",
      "            }}\n",
      "        }},\n",
      "        \"0_screencapture_uuid\": {{\n",
      "            \"name\": \"screenCapture\",\n",
      "            \"restrictions\": [\n",
      "                {{\n",
      "                    \"cred_def_id\": \"{CD_ID}\"\n",
      "                }}\n",
      "            ],\n",
      "            \"non_revoked\": {{\n",
      "                \"from\": {NOW_EPOCH},\n",
      "                \"to\": {NOW_EPOCH}\n",
      "            }}\n",
      "        }}\n",
      "    }},\n",
      "    \"requested_predicates\": {{\n",
      "        \"0_highscore_GE_uuid\": {{\n",
      "            \"name\": \"highScore\",\n",
      "            \"p_type\": \">=\",\n",
      "            \"p_value\": 1000000,\n",
      "            \"restrictions\": [\n",
      "                {{\n",
      "                    \"cred_def_id\": \"{CD_ID}\"\n",
      "                }}\n",
      "            ],\n",
      "            \"non_revoked\": {{\n",
      "                \"from\": {NOW_EPOCH},\n",
      "                \"to\": {NOW_EPOCH}\n",
      "            }}\n",
      "        }}\n",
      "    }}\n",
      "}}\"\"\"\n",
      ")\n",
      "\n",
      "PRES_REQ = PresentationRequest(\n",
      "    comment=\"Test\",\n",
      "    request_presentations_attach=[\n",
      "        AttachDecorator.data_base64(\n",
      "            mapping=INDY_PROOF_REQ,\n",
      "            ident=ATTACH_DECO_IDS[PRESENTATION_REQUEST],\n",
      "        )\n",
      "    ],\n",
      ")\n",
      "\n",
      "\n",
      "class TestPresentationRequest(TestCase):\n",
      "    \"\"\"Presentation request tests.\"\"\"\n",
      "\n",
      "    def test_init(self):\n",
      "        \"\"\"Test initializer.\"\"\"\n",
      "        assert PRES_REQ.request_presentations_attach[0].content == INDY_PROOF_REQ\n",
      "        assert PRES_REQ.indy_proof_request(0) == INDY_PROOF_REQ\n",
      "\n",
      "    def test_type(self):\n",
      "        \"\"\"Test type.\"\"\"\n",
      "        assert PRES_REQ._type == DIDCommPrefix.qualify_current(PRESENTATION_REQUEST)\n",
      "\n",
      "    def test_deserialize(self):\n",
      "        \"\"\"Test deserialization.\"\"\"\n",
      "        dump = json.dumps(\n",
      "            {\n",
      "                \"@type\": DIDCommPrefix.qualify_current(PRESENTATION_REQUEST),\n",
      "                \"comment\": \"Hello World\",\n",
      "                \"request_presentations~attach\": [\n",
      "                    AttachDecorator.data_base64(\n",
      "                        mapping=INDY_PROOF_REQ,\n",
      "                        ident=ATTACH_DECO_IDS[PRESENTATION_REQUEST],\n",
      "                    ).serialize()\n",
      "                ],\n",
      "            }\n",
      "        )\n",
      "\n",
      "        presentation_request = PresentationRequest.deserialize(dump)\n",
      "        assert type(presentation_request) == PresentationRequest\n",
      "\n",
      "    def METHOD_NAME(self):\n",
      "        \"\"\"Test serialization.\"\"\"\n",
      "        pres_req_dict = PRES_REQ.serialize()\n",
      "        pres_req_dict.pop(\"@id\")\n",
      "\n",
      "        assert pres_req_dict == {\n",
      "            \"@type\": DIDCommPrefix.qualify_current(PRESENTATION_REQUEST),\n",
      "            \"request_presentations~attach\": [\n",
      "                AttachDecorator.data_base64(\n",
      "                    mapping=INDY_PROOF_REQ,\n",
      "                    ident=ATTACH_DECO_IDS[PRESENTATION_REQUEST],\n",
      "                ).serialize()\n",
      "            ],\n",
      "            \"comment\": \"Test\",\n",
      "        }\n",
      "\n",
      "\n",
      "class TestPresentationRequestSchema(TestCase):\n",
      "    \"\"\"Test presentation request schema\"\"\"\n",
      "\n",
      "    def test_make_model(self):\n",
      "        \"\"\"Test making model.\"\"\"\n",
      "        pres_req_dict = PRES_REQ.serialize()\n",
      "        \"\"\"\n",
      "        Looks like: {\n",
      "            \"@type\": \".../present-proof/1.0/request-presentation\",\n",
      "            \"@id\": \"f49773e3-bd56-4868-a5f1-456d1e6d1a16\",\n",
      "            \"comment\": \"Test\",\n",
      "            \"request_presentations~attach\": [\n",
      "                {\n",
      "                    \"mime-type\": \"application/json\",\n",
      "                    \"data\": {\n",
      "                        \"base64\": \"eyJuYW...\"\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "        \"\"\"\n",
      "\n",
      "        model_instance = PRES_REQ.deserialize(pres_req_dict)\n",
      "        assert isinstance(model_instance, PresentationRequest)\n",
      "====================\n",
      "\n",
      "process one version\n",
      "====================\n",
      "# (C) Datadog, Inc. 2023-present\n",
      "# All rights reserved\n",
      "# Licensed under a 3-clause BSD style license (see LICENSE)\n",
      "import copy\n",
      "import json\n",
      "import time\n",
      "from urllib.parse import urljoin\n",
      "\n",
      "from datadog_checks.base import AgentCheck\n",
      "from datadog_checks.torchserve.model_discovery import ModelDiscovery\n",
      "\n",
      "WORKER_STATUSES = {\n",
      "    \"UNKNOWN\": 0,\n",
      "    \"READY\": 1,\n",
      "    \"LOADING\": 2,\n",
      "    \"UNLOADING\": 3,\n",
      "}\n",
      "\n",
      "\n",
      "class TorchserveManagementAPICheck(AgentCheck):\n",
      "    __NAMESPACE__ = 'torchserve.management_api'\n",
      "    SERVICE_CHECK_NAME = 'health'\n",
      "    CHECK_NAME = \"torchserve\"\n",
      "\n",
      "    def __init__(self, *args, **kwargs):\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.model_discovery = None\n",
      "        self.submit_events = None\n",
      "        self.tags = None\n",
      "        self.__previous_models = None\n",
      "        self.check_initializations.append(self.parse_config)\n",
      "\n",
      "    def parse_config(self):\n",
      "        self.model_discovery = ModelDiscovery(\n",
      "            self,\n",
      "            limit=self.instance.get(\"limit\", 100),\n",
      "            include=self.instance.get(\"include\", [\".*\"]),\n",
      "            exclude=self.instance.get(\"exclude\", []),\n",
      "            interval=self.instance.get(\"interval\"),\n",
      "        )\n",
      "        self.submit_events = self.instance.get(\"submit_events\", True)\n",
      "        self.tags = self.instance.get(\"tags\", [])\n",
      "        self.tags.append(f\"management_api_url:{self.instance['management_api_url']}\")\n",
      "\n",
      "    def check(self, _):\n",
      "        for _, _, model, _ in self.model_discovery.get_items():\n",
      "            self.process_one_model(model)\n",
      "\n",
      "        self.service_check(self.SERVICE_CHECK_NAME, self.model_discovery.api_status, tags=self.tags)\n",
      "\n",
      "        if self.model_discovery.api_status == AgentCheck.OK and self.submit_events and self.model_discovery.refreshed:\n",
      "            if self.previous_models is not None:\n",
      "                self.compare_models_and_emit_events(self.previous_models, self.model_discovery.all_models)\n",
      "\n",
      "            self.previous_models = self.model_discovery.all_models\n",
      "\n",
      "    def process_one_model(self, model):\n",
      "        self.log.debug(\"Processing model [%s]\", model['modelName'])\n",
      "        model_name = model['modelName']\n",
      "        endpoint = f\"models/{model_name}/all\"\n",
      "        url = urljoin(self.instance[\"management_api_url\"], endpoint)\n",
      "\n",
      "        try:\n",
      "            response = self.http.get(url)\n",
      "            response.raise_for_status()\n",
      "            content = response.json()\n",
      "        except Exception as e:\n",
      "            self.log.error(\"Caught exception %s querying model %s.\", e, model_name)\n",
      "            return\n",
      "\n",
      "        self.gauge(\"model.versions\", len(content), tags=self.tags + [f\"model_name:{model_name}\"])\n",
      "\n",
      "        for model_details in content:\n",
      "            self.METHOD_NAME(model, model_details)\n",
      "\n",
      "    def METHOD_NAME(self, model, model_details):\n",
      "        self.log.debug(\n",
      "            \"Processing version [%s] for model [%s]\", model_details['modelVersion'], model_details['modelName']\n",
      "        )\n",
      "\n",
      "        tags = copy.deepcopy(self.tags)\n",
      "        tags += [f\"model_name:{model_details['modelName']}\", f\"model_version:{model_details['modelVersion']}\"]\n",
      "\n",
      "        self.gauge(\"model.workers.current\", len(model_details.get(\"workers\", [])), tags=tags)\n",
      "        self.gauge(\"model.workers.min\", model_details.get(\"minWorkers\"), tags=tags)\n",
      "        self.gauge(\"model.workers.max\", model_details.get(\"maxWorkers\"), tags=tags)\n",
      "        self.gauge(\"model.batch_size\", model_details.get(\"batchSize\"), tags=tags)\n",
      "        self.gauge(\"model.max_batch_delay\", model_details.get(\"maxBatchDelay\"), tags=tags)\n",
      "        self.gauge(\"model.is_loaded_at_startup\", 1 if model_details.get(\"loadedAtStartup\", False) else 0, tags=tags)\n",
      "        self.gauge(\n",
      "            \"model.version.is_default\", 1 if model_details.get(\"modelUrl\") == model.get(\"modelUrl\") else 0, tags=tags\n",
      "        )\n",
      "\n",
      "        for worker in model_details.get(\"workers\", []):\n",
      "            self.process_one_worker(worker, model_details, tags)\n",
      "\n",
      "    def process_one_worker(self, worker, model_details, model_tags):\n",
      "        self.log.debug(\n",
      "            \"Processing worker [%s] for version [%s] of model [%s]\",\n",
      "            worker[\"id\"],\n",
      "            model_details['modelVersion'],\n",
      "            model_details['modelName'],\n",
      "        )\n",
      "\n",
      "        tags = model_tags + [\n",
      "            f\"worker_id:{worker.get('id')}\",\n",
      "            f\"worker_pid:{worker.get('pid')}\",\n",
      "        ]\n",
      "\n",
      "        self.gauge(\"model.worker.memory_usage\", worker.get(\"memoryUsage\"), tags=tags)\n",
      "        self.gauge(\"model.worker.is_gpu\", 1 if worker.get(\"gpu\", False) else 0, tags=tags)\n",
      "        self.gauge(\"model.worker.status\", WORKER_STATUSES.get(worker.get(\"status\"), 0), tags=tags)\n",
      "\n",
      "    @property\n",
      "    def previous_models(self):\n",
      "        if self.__previous_models:\n",
      "            return self.__previous_models\n",
      "\n",
      "        if previous_models := self.read_persistent_cache(\"previous_models\"):\n",
      "            self.__previous_models = json.loads(previous_models)\n",
      "            return self.__previous_models\n",
      "\n",
      "        return None\n",
      "\n",
      "    @previous_models.setter\n",
      "    def previous_models(self, value):\n",
      "        self.__previous_models = value\n",
      "        self.write_persistent_cache(\"previous_models\", json.dumps(value))\n",
      "\n",
      "    def compare_models_and_emit_events(self, previous_models, current_models):\n",
      "        for previous_key, previous_value in previous_models.items():\n",
      "            current_value = current_models.get(previous_key)\n",
      "\n",
      "            if not current_value:\n",
      "                self.log.debug(\"Model [%s] has been removed\", previous_key)\n",
      "                self.event(\n",
      "                    self.__create_event(\n",
      "                        f\"{self.__NAMESPACE__}.model_removed\",\n",
      "                        \"A model has been removed\",\n",
      "                        f\"The model [{previous_key}] has been removed.\",\n",
      "                        self.tags + [f\"model_name:{previous_key}\"],\n",
      "                    ),\n",
      "                )\n",
      "                continue\n",
      "\n",
      "            if current_value != previous_value:\n",
      "                self.log.debug(\n",
      "                    \"New default value for model [%s] set from [%s] to [%s]\",\n",
      "                    previous_key,\n",
      "                    previous_value,\n",
      "                    current_value,\n",
      "                )\n",
      "                self.event(\n",
      "                    self.__create_event(\n",
      "                        f\"{self.__NAMESPACE__}.default_version_changed\",\n",
      "                        \"A new default version has been set for a model\",\n",
      "                        f\"A new default version has been set for the model [{previous_key}], \"\n",
      "                        f\"from file [{previous_value}] to file [{current_value}].\",\n",
      "                        self.tags + [f\"model_name:{previous_key}\"],\n",
      "                    )\n",
      "                )\n",
      "\n",
      "        for model_name, model_url in [(k, v) for (k, v) in current_models.items() if k not in previous_models]:\n",
      "            self.log.debug(\"Model [%s] has been added\", model_name)\n",
      "            self.event(\n",
      "                self.__create_event(\n",
      "                    f\"{self.__NAMESPACE__}.model_added\",\n",
      "                    \"A new model has been added\",\n",
      "                    f\"The model [{model_name}] has been added with the file [{model_url}].\",\n",
      "                    self.tags + [f\"model_name:{model_name}\"],\n",
      "                ),\n",
      "            )\n",
      "\n",
      "    def __create_event(self, type, title, message, tags):\n",
      "        return {\n",
      "            'timestamp': time.time(),\n",
      "            'event_type': type,\n",
      "            'msg_title': title,\n",
      "            'msg_text': message,\n",
      "            'alert_type': 'info',\n",
      "            'source_type_name': self.CHECK_NAME,\n",
      "            'host': self.hostname,\n",
      "            'tags': tags,\n",
      "        }\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "perm = t.randperm(len(codes))\n",
    "for i in perm[:10].tolist():\n",
    "    print(df[\"label\"][i])\n",
    "    print(\"=\" * 20)\n",
    "    print(codes[i])\n",
    "    print(\"=\" * 20)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up class\n",
      "def METHOD_NAME(cls):\n",
      "    super().METHOD_NAME(DominicanRepublic)\n",
      "====================\n",
      "str indent\n",
      "def METHOD_NAME(self, doc, indent=4):\n",
      "    out = []\n",
      "    for line in doc:\n",
      "        out += [' '*indent + line]\n",
      "    return out\n",
      "====================\n",
      "set mkl envs\n",
      "def METHOD_NAME(job_name):\n",
      "  envs = []\n",
      "  if \"ps\" == job_name:\n",
      "    envs.append(\"OMP_NUM_THREADS=1\")\n",
      "    envs.append(\"KMP_BLOCKTIME=0\")\n",
      "    envs.append(\"MKL_ENABLE_INSTRUCTIONS=AVX2\")\n",
      "  elif \"worker\" == job_name:\n",
      "    envs.append(\"OMP_NUM_THREADS=6\")\n",
      "    envs.append(\"KMP_BLOCKTIME=0\")\n",
      "    envs.append(\"MKL_ENABLE_INSTRUCTIONS=AVX2\")\n",
      "  elif \"evaluator\" == job_name or \"chief\" == job_name:\n",
      "    envs.append(\"OMP_NUM_THREADS=1\")\n",
      "    envs.append(\"KMP_BLOCKTIME=0\")\n",
      "    envs.append(\"MKL_ENABLE_INSTRUCTIONS=AVX2\")\n",
      "  else:\n",
      "    envs.append(\"OMP_NUM_THREADS=1\")\n",
      "    envs.append(\"KMP_BLOCKTIME=0\")\n",
      "    envs.append(\"MKL_ENABLE_INSTRUCTIONS=AVX2\")\n",
      "  return envs\n",
      "====================\n",
      "asym enc\n",
      "def METHOD_NAME(k, m):\n",
      "    return k.encrypt(\n",
      "        m,\n",
      "        asymmetric.padding.OAEP(\n",
      "            mgf=asymmetric.padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None\n",
      "        ),\n",
      "    )\n",
      "====================\n",
      "test monitors pg\n",
      "def METHOD_NAME():\n",
      "    test_data = load_tests(\"monitors\", \"peer-group.conf\")\n",
      "    run_tests(\"monitors_pg\", *test_data)\n",
      "====================\n",
      "webhook payment gateway initialize tokenization response\n",
      "def METHOD_NAME():\n",
      "    return {\n",
      "        \"result\": (\n",
      "            PaymentGatewayInitializeTokenizationResult.SUCCESSFULLY_INITIALIZED.name\n",
      "        ),\n",
      "        \"data\": {\"foo\": \"bar\"},\n",
      "    }\n",
      "====================\n",
      "test mobile get unauthenticated user\n",
      "def METHOD_NAME(self):\n",
      "    self.client.logout()\n",
      "    response = self.client.get(reverse('course-experience-course-deadlines-mobile', args=[self.course.id]))\n",
      "    assert response.status_code == 401\n",
      "====================\n",
      "run test\n",
      "def METHOD_NAME():\n",
      "    \"Run through the tests one by one\"\n",
      "    print (\"Checking we can step the first few instructions\")\n",
      "    step_ok = 0\n",
      "    for i in range(3):\n",
      "        if check_step():\n",
      "            step_ok += 1\n",
      "    report(step_ok == 3, \"single step in boot code\")\n",
      "    print (\"Checking HW breakpoint works\")\n",
      "    break_ok = check_hbreak(\"kernel_init\")\n",
      "    report(break_ok, \"hbreak @ kernel_init\")\n",
      "    # Can't set this up until we are in the kernel proper\n",
      "    # if we make it to run_init_process we've over-run and\n",
      "    # one of the tests failed\n",
      "    print (\"Setup catch-all for run_init_process\")\n",
      "    cbp = CatchBreakpoint(\"run_init_process\")\n",
      "    cpb2 = CatchBreakpoint(\"try_to_run_init_process\")\n",
      "    print (\"Checking Normal breakpoint works\")\n",
      "    break_ok = check_break(\"wait_for_completion\")\n",
      "    report(break_ok, \"break @ wait_for_completion\")\n",
      "    print (\"Checking watchpoint works\")\n",
      "    check_watches(\"system_state\")\n",
      "====================\n",
      "fp16 to fp32\n",
      "def METHOD_NAME(tensor: torch.Tensor) -> torch.Tensor:\n",
      "    return tensor.float()\n",
      "====================\n",
      "get six digit naics count\n",
      "def METHOD_NAME(self, code: str) -> int:\n",
      "    return self.naics_queryset.filter(code__startswith=code, text_len=6).count()\n",
      "====================\n",
      "test ties broken alphabetically\n",
      "def METHOD_NAME(self):\n",
      "    results = [\n",
      "        \"Courageous Californians;Devastating Donkeys;win\",\n",
      "        \"Allegoric Alaskans;Blithering Badgers;win\",\n",
      "        \"Devastating Donkeys;Allegoric Alaskans;loss\",\n",
      "        \"Courageous Californians;Blithering Badgers;win\",\n",
      "        \"Blithering Badgers;Devastating Donkeys;draw\",\n",
      "        \"Allegoric Alaskans;Courageous Californians;draw\",\n",
      "    ]\n",
      "    table = [\n",
      "        \"Team                           | MP |  W |  D |  L |  P\",\n",
      "        \"Allegoric Alaskans             |  3 |  2 |  1 |  0 |  7\",\n",
      "        \"Courageous Californians        |  3 |  2 |  1 |  0 |  7\",\n",
      "        \"Blithering Badgers             |  3 |  0 |  1 |  2 |  1\",\n",
      "        \"Devastating Donkeys            |  3 |  0 |  1 |  2 |  1\",\n",
      "    ]\n",
      "    self.assertEqual(tally(results), table)\n",
      "====================\n",
      "get severity level\n",
      "severity_level = METHOD_NAME(log_record.severity_number)\n",
      "====================\n",
      "delete empty color blocks\n",
      "def METHOD_NAME(self):\n",
      "    color_blocks = []\n",
      "    for color_block in self.color_blocks:\n",
      "        if len(color_block) > 0:\n",
      "            color_blocks.append(color_block)\n",
      "    self.color_blocks = color_blocks\n",
      "====================\n",
      "test print topic help with devel for\n",
      "def METHOD_NAME(self):\n",
      "    expected = {\n",
      "        \"sources\": \"Help on package snapcraft\",\n",
      "        \"plugins\": \"Help on package snapcraft\",\n",
      "    }\n",
      "    for topic in _TOPICS:\n",
      "        result = self.run_command([\"help\", topic, \"--devel\"])\n",
      "        output = result.output[: len(expected[topic])]\n",
      "        self.assertThat(\n",
      "            output,\n",
      "            Equals(expected[topic]),\n",
      "            \"The help message does not start with {!r} but with \"\n",
      "            \"{!r} instead\".format(expected[topic], output),\n",
      "        )\n",
      "====================\n",
      "test type raises for unknown type of\n",
      "def METHOD_NAME(factories):\n",
      "    group = factories.Group()\n",
      "    # Set the group's access flags to an invalid / unused combination.\n",
      "    group.joinable_by = None\n",
      "    group.readable_by = ReadableBy.members\n",
      "    group.writeable_by = WriteableBy.authority\n",
      "    expected_err = \"^This group doesn't seem to match any known type\"\n",
      "    with pytest.raises(ValueError, match=expected_err):\n",
      "        _ = group.type\n",
      "====================\n",
      "prep param lists\n",
      "def METHOD_NAME(model, flat_master=False):\n",
      "    \"\"\"\n",
      "    Creates a list of FP32 master parameters for a given model, as in\n",
      "    `Training Neural Networks with Mixed Precision:  Real Examples`_.\n",
      "    Args:\n",
      "        model (torch.nn.Module): Existing Pytorch model\n",
      "        flat_master (bool, optional, default=False):  Flatten the master parameters into a single tensor, as a performance optimization.\n",
      "    Returns:\n",
      "        A tuple (``model_params``, ``master_params``). ``model_params`` is a list of the model's parameters for later use with :func:`model_grads_to_master_grads` and :func:`master_params_to_model_params`.  ``master_params`` is a list of FP32 master gradients.  If ``flat_master=True``, ``master_params`` will be a list with one element.\n",
      "    Example::\n",
      "        model_params, master_params = prep_param_lists(model)\n",
      "    .. warning::\n",
      "        Currently, if ``flat_master=True``, all the model's parameters must be the same type.  If the model has parameters of different types, use ``flat_master=False``, or use :class:`FP16_Optimizer`.\n",
      "    .. _`Training Neural Networks with Mixed Precision:  Real Examples`:\n",
      "        http://on-demand.gputechconf.com/gtc/2018/video/S81012/\n",
      "    \"\"\"\n",
      "    model_params = [param for param in model.parameters() if param.requires_grad]\n",
      "    if flat_master:\n",
      "        # Give the user some more useful error messages\n",
      "        try:\n",
      "            # flatten_dense_tensors returns a contiguous flat array.\n",
      "            # http://pytorch.org/docs/master/_modules/torch/_utils.html\n",
      "            master_params = _flatten_dense_tensors([param.data for param in model_params]).float()\n",
      "        except:\n",
      "            print(\"Error in prep_param_lists:  model may contain a mixture of parameters \"\n",
      "                      \"of different types.  Use flat_master=False, or use F16_Optimizer.\")\n",
      "            raise\n",
      "        master_params = torch.nn.Parameter(master_params)\n",
      "        master_params.requires_grad = True\n",
      "        # master_params.register_hook(backwards_debug_hook)\n",
      "        if master_params.grad is None:\n",
      "            master_params.grad = master_params.new(*master_params.size())\n",
      "        return model_params, [master_params]\n",
      "    else:\n",
      "        master_params = [param.clone().float().detach() for param in model_params]\n",
      "        for param in master_params:\n",
      "            param.requires_grad = True\n",
      "        return model_params, master_params\n",
      "====================\n",
      "test results display\n",
      "def METHOD_NAME():\n",
      "    phase = PhaseFactory()\n",
      "    user1 = UserFactory()\n",
      "    user2 = UserFactory()\n",
      "    metrics = \"metrics\"\n",
      "    creator = \"creator\"\n",
      "    results = [\n",
      "        {metrics: {\"b\": 0.3}, creator: user1},  # Invalid result\n",
      "        {metrics: {\"a\": 0.6}, creator: user1},\n",
      "        {metrics: {\"a\": 0.4}, creator: user1},\n",
      "        {metrics: {\"a\": 0.2}, creator: user1},\n",
      "        {metrics: {\"a\": 0.1}, creator: user2},\n",
      "        {metrics: {\"a\": 0.5}, creator: user2},\n",
      "        {metrics: {\"a\": 0.3}, creator: user2},\n",
      "    ]\n",
      "    queryset = [\n",
      "        EvaluationFactory(\n",
      "            submission__phase=phase,\n",
      "            submission__creator=r[creator],\n",
      "            status=Evaluation.SUCCESS,\n",
      "        )\n",
      "        for r in results\n",
      "    ]\n",
      "    for e, r in zip(queryset, results, strict=True):\n",
      "        e.outputs.add(\n",
      "            ComponentInterfaceValue.objects.create(\n",
      "                interface=ComponentInterface.objects.get(\n",
      "                    slug=\"metrics-json-file\"\n",
      "                ),\n",
      "                value=r[metrics],\n",
      "            )\n",
      "        )\n",
      "    phase.score_jsonpath = \"a\"\n",
      "    phase.result_display_choice = Phase.ALL\n",
      "    phase.save()\n",
      "    calculate_ranks(phase_pk=phase.pk)\n",
      "    expected_ranks = [0, 1, 3, 5, 6, 2, 4]\n",
      "    assert_ranks(queryset, expected_ranks)\n",
      "    phase.result_display_choice = Phase.MOST_RECENT\n",
      "    phase.save()\n",
      "    calculate_ranks(phase_pk=phase.pk)\n",
      "    expected_ranks = [0, 0, 0, 2, 0, 0, 1]\n",
      "    assert_ranks(queryset, expected_ranks)\n",
      "    phase.result_display_choice = Phase.BEST\n",
      "    phase.save()\n",
      "    calculate_ranks(phase_pk=phase.pk)\n",
      "    expected_ranks = [0, 1, 0, 0, 0, 2, 0]\n",
      "    assert_ranks(queryset, expected_ranks)\n",
      "    # now test reverse order\n",
      "    phase.score_default_sort = phase.ASCENDING\n",
      "    phase.save()\n",
      "    calculate_ranks(phase_pk=phase.pk)\n",
      "    expected_ranks = [0, 0, 0, 2, 1, 0, 0]\n",
      "    assert_ranks(queryset, expected_ranks)\n",
      "    phase.result_display_choice = Phase.MOST_RECENT\n",
      "    phase.save()\n",
      "    calculate_ranks(phase_pk=phase.pk)\n",
      "    expected_ranks = [0, 0, 0, 1, 0, 0, 2]\n",
      "    assert_ranks(queryset, expected_ranks)\n",
      "====================\n",
      "nptensor2np\n",
      "def METHOD_NAME(\n",
      "    img: np.ndarray,\n",
      "    rgb2bgr=True,\n",
      "    remove_batch=True,\n",
      "    data_range=255,\n",
      "    denormalize=False,\n",
      "    change_range=True,\n",
      "    imtype: Type = np.uint8,\n",
      ") -> np.ndarray:\n",
      "    \"\"\"Converts a Tensor array into a numpy image array.\n",
      "    Parameters:\n",
      "        img (tensor): the input image tensor array\n",
      "            4D(B,(3/1),H,W), 3D(C,H,W), or 2D(H,W), any range, RGB channel order\n",
      "        remove_batch (bool): choose if tensor of shape BCHW needs to be squeezed\n",
      "        denormalize (bool): Used to denormalize from [-1,1] range back to [0,1]\n",
      "        imtype (type): the desired type of the converted numpy array (np.uint8\n",
      "            default)\n",
      "    Output:\n",
      "        img (np array): 3D(H,W,C) or 2D(H,W), [0,255], np.uint8 (default)\n",
      "    \"\"\"\n",
      "    n_dim = img.ndim\n",
      "    img = img.astype(np.float32)\n",
      "    if n_dim in (4, 3):\n",
      "        # if n_dim == 4, has to convert to 3 dimensions\n",
      "        if n_dim == 4 and remove_batch:\n",
      "            # remove a fake batch dimension\n",
      "            img = img.squeeze(0)\n",
      "        if img.shape[0] == 3 and rgb2bgr:  # RGB\n",
      "            # RGB to BGR -> in tensor, if using OpenCV, else not needed. Only if image has colors.\n",
      "            img_np = np_rgb_to_bgr(img)\n",
      "        elif img.shape[0] == 4 and rgb2bgr:  # RGBA\n",
      "            # RGBA to BGRA -> in tensor, if using OpenCV, else not needed. Only if image has colors.\n",
      "            img_np = np_rgba_to_bgra(img)\n",
      "        else:\n",
      "            img_np = img\n",
      "        img_np = np.transpose(img_np, (1, 2, 0))  # CHW to HWC\n",
      "    elif n_dim == 2:\n",
      "        img_np = img\n",
      "    else:\n",
      "        raise TypeError(\n",
      "            f\"Only support 4D, 3D and 2D tensor. But received with dimension: {n_dim:d}\"\n",
      "        )\n",
      "    # if rgb2bgr:\n",
      "    # img_np = img_np[[2, 1, 0], :, :] #RGB to BGR -> in numpy, if using OpenCV, else not needed. Only if image has colors.\n",
      "    # TODO: Check: could denormalize in the begining in tensor form instead\n",
      "    if denormalize:\n",
      "        img_np = np_denorm(img_np)  # denormalize if needed\n",
      "    if change_range:\n",
      "        img_np = np.clip(\n",
      "            data_range * img_np, 0, data_range  # type: ignore\n",
      "        ).round()  # np.clip to the data_range\n",
      "    # has to be in range (0,255) before changing to np.uint8, else np.float32\n",
      "    return img_np.astype(imtype)\n",
      "====================\n",
      "simple policy\n",
      "def METHOD_NAME(oso):\n",
      "    \"\"\"Load a simple base policy into oso.\"\"\"\n",
      "    oso.load_file(Path(__file__).parent / \"simple.polar\")\n",
      "====================\n",
      "slice\n",
      "def METHOD_NAME(self, i=None, j=None):\n",
      "    \"\"\"Return a view of the list of tokens from [i, j).\"\"\"\n",
      "    new_tokens = copy.copy(self)\n",
      "    new_tokens.data = self.data[i: j]\n",
      "    return new_tokens\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from parse import parse_method\n",
    "\n",
    "for code, label in zip(codes[:20], df[\"label\"][:20].tolist()):\n",
    "    print(label)\n",
    "    print(parse_method(code))\n",
    "    print(\"=\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def METHOD_NAME(oso):\n",
    "    \"\"\"Load a simple base policy into oso.\"\"\"\n",
    "    oso.load_file(Path(__file__).parent / \"simple.polar\")\n",
    "\n",
    "METHOD_NAME = simple_policy\n",
    "\n",
    "def METHOD_NAME(self, i=None, j=None):\n",
    "    \"\"\"Return a view of the list of tokens from [i, j).\"\"\"\n",
    "    new_tokens = copy.copy(self)\n",
    "    new_tokens.data = self.data[i: j]\n",
    "\n",
    "METHOD_NAME = slice\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
